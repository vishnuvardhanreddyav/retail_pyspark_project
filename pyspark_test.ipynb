{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/31 11:49:28 WARN Utils: Your hostname, Vishnus-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.2 instead (on interface en0)\n",
      "24/12/31 11:49:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/31 11:49:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "            .master(\"local[2]\") \\\n",
    "            .config('spark.shuffle.useOldFetchProtocol', 'true') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_schema = \"customer_id int,customer_fname string,customer_lname string,username string,password string,address string,city string,state string,pincode string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_df = spark.read.format(\"csv\").option(\"header\",True).schema(customers_schema).load(\"/Users/avvishnuvardhanreddy/Documents/My_Learning/Personal/Big_data_trendytech/retail_pyspark_project/data/customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+--------------+---------+---------+--------------------+-------------+-----+-------+\n",
      "|customer_id|customer_fname|customer_lname| username| password|             address|         city|state|pincode|\n",
      "+-----------+--------------+--------------+---------+---------+--------------------+-------------+-----+-------+\n",
      "|          1|       Richard|     Hernandez|XXXXXXXXX|XXXXXXXXX|  6303 Heather Plaza|  Brownsville|   TX|  78521|\n",
      "|          2|          Mary|       Barrett|XXXXXXXXX|XXXXXXXXX|9526 Noble Embers...|    Littleton|   CO|  80126|\n",
      "|          3|           Ann|         Smith|XXXXXXXXX|XXXXXXXXX|3422 Blue Pioneer...|       Caguas|   PR|  00725|\n",
      "|          4|          Mary|         Jones|XXXXXXXXX|XXXXXXXXX|  8324 Little Common|   San Marcos|   CA|  92069|\n",
      "|          5|        Robert|        Hudson|XXXXXXXXX|XXXXXXXXX|10 Crystal River ...|       Caguas|   PR|  00725|\n",
      "|          6|          Mary|         Smith|XXXXXXXXX|XXXXXXXXX|3151 Sleepy Quail...|      Passaic|   NJ|  07055|\n",
      "|          7|       Melissa|        Wilcox|XXXXXXXXX|XXXXXXXXX|9453 High Concession|       Caguas|   PR|  00725|\n",
      "|          8|         Megan|         Smith|XXXXXXXXX|XXXXXXXXX|3047 Foggy Forest...|     Lawrence|   MA|  01841|\n",
      "|          9|          Mary|         Perez|XXXXXXXXX|XXXXXXXXX| 3616 Quaking Street|       Caguas|   PR|  00725|\n",
      "|         10|       Melissa|         Smith|XXXXXXXXX|XXXXXXXXX|8598 Harvest Beac...|     Stafford|   VA|  22554|\n",
      "|         11|          Mary|       Huffman|XXXXXXXXX|XXXXXXXXX|    3169 Stony Woods|       Caguas|   PR|  00725|\n",
      "|         12|   Christopher|         Smith|XXXXXXXXX|XXXXXXXXX|5594 Jagged Ember...|  San Antonio|   TX|  78227|\n",
      "|         13|          Mary|       Baldwin|XXXXXXXXX|XXXXXXXXX|7922 Iron Oak Gar...|       Caguas|   PR|  00725|\n",
      "|         14|     Katherine|         Smith|XXXXXXXXX|XXXXXXXXX|5666 Hazy Pony Sq...|  Pico Rivera|   CA|  90660|\n",
      "|         15|          Jane|          Luna|XXXXXXXXX|XXXXXXXXX|    673 Burning Glen|      Fontana|   CA|  92336|\n",
      "|         16|       Tiffany|         Smith|XXXXXXXXX|XXXXXXXXX|      6651 Iron Port|       Caguas|   PR|  00725|\n",
      "|         17|          Mary|      Robinson|XXXXXXXXX|XXXXXXXXX|     1325 Noble Pike|       Taylor|   MI|  48180|\n",
      "|         18|        Robert|         Smith|XXXXXXXXX|XXXXXXXXX|2734 Hazy Butterf...|     Martinez|   CA|  94553|\n",
      "|         19|     Stephanie|      Mitchell|XXXXXXXXX|XXXXXXXXX|3543 Red Treasure...|       Caguas|   PR|  00725|\n",
      "|         20|          Mary|         Ellis|XXXXXXXXX|XXXXXXXXX|      4703 Old Route|West New York|   NJ|  07093|\n",
      "+-----------+--------------+--------------+---------+---------+--------------------+-------------+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_state_agg_df =customers_df.groupBy(\"state\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|state|count|\n",
      "+-----+-----+\n",
      "|   AZ|  213|\n",
      "|   SC|   41|\n",
      "|   LA|   63|\n",
      "|   MN|   39|\n",
      "|   NJ|  219|\n",
      "|   DC|   42|\n",
      "|   OR|  119|\n",
      "|   VA|  136|\n",
      "|   RI|   15|\n",
      "|   KY|   35|\n",
      "|   MI|  254|\n",
      "|   NV|  103|\n",
      "|   WI|   64|\n",
      "|   ID|    9|\n",
      "|   CA| 2012|\n",
      "|   CT|   73|\n",
      "|   MT|    7|\n",
      "|   NC|  150|\n",
      "|   MD|  164|\n",
      "|   DE|   23|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cust_state_agg_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_state_agg_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 22:44:22 WARN ParseMode: overwrite is not a valid parse mode. Using PERMISSIVE.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cust_state_agg_df.write.format(\"csv\").option(\"header\",True).option(\"mode\",\"overwrite\").option(\"path\",\"data/expected_results\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retail_pyspark_project-31qol5B4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
